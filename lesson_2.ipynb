{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Import libraries\n",
    "import math\n",
    "import os\n",
    "from six.moves import xrange\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.2 Define some constants\n",
    "# The MNIST dataset has 10 classes, representing the digits 0 through 9\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# The MINST images are always 28x28 pixels\n",
    "IMAGE_SIZE = 28\n",
    "IMAGE_PIXELS = IMAGE_SIZE * IMAGE_SIZE\n",
    "\n",
    "# Batch size. Must be evenly dividedable by dataset sizes.\n",
    "BATCH_SIZE = 100\n",
    "EVAL_BATCH_SIZE = 1\n",
    "\n",
    "# Number of units in hidden layers\n",
    "HIDDEN1_UNITS = 128\n",
    "HIDDEN2_UNITS = 32\n",
    "\n",
    "# Maximum number of training steps\n",
    "MAX_STEPS = 2000\n",
    "\n",
    "# Directory to put the training data.\n",
    "TRAIN_DIR=\"/tmp/mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Get input data: get the sets of images and labels for training, validatest test on MNSIT.\n",
    "data_sets = read_data_sets(TRAIN_DIR, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.4 Build inference graph.\n",
    "def mnist_inference(images, hidden1_units, hidden2_units):\n",
    "    \"\"\"Build the MNIST model up to where it may be used for inference.\n",
    "    Args:\n",
    "        images: Image placeholder\n",
    "        hidden1_units: Size of the first hidden layer\n",
    "        hidden2_units: Size of the second hidden layer\n",
    "    Returns:\n",
    "        logits: Output tensor with the computed logits\n",
    "    \"\"\"\n",
    "    # Hidden 1\n",
    "    with tf.name_scope('hidden1'):\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "            [IMAGE_PIXELS, hidden1_units],\n",
    "            stddev=1.0 / math.sqrt(float(IMAGE_PIXELS))\n",
    "        ), name='weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden1_units]), name = 'biases')\n",
    "        hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)\n",
    "    # Hidden 2\n",
    "    with tf.name_scope('hidden2'):\n",
    "        weights= tf.Variable(tf.truncated_normal(\n",
    "            [hidden1_units, hidden2_units],\n",
    "            stddev = 1.0 / math.sqrt(float(hidden1_units))\n",
    "        ), name = 'weights')\n",
    "        biases = tf.Variable(tf.zeros([hidden2_units]), name = \"biases\")\n",
    "        hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "    # Linear\n",
    "    with tf.name_scope('softmax_linear'):\n",
    "        weights = tf.Variable(tf.truncated_normal(\n",
    "            [hidden2_units, NUM_CLASSES],\n",
    "            stddev = 1.0 / math.sqrt(float(hidden2_units))\n",
    "        ), name = 'weights')\n",
    "        biases = tf.Variable(tf.zeros([NUM_CLASSES]), name=\"biases\")\n",
    "        logits = tf.matmul(hidden2, weights) + biases\n",
    "        \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2.5 Build training graph\n",
    "def mnist_training(logits, labels, learning_rate):\n",
    "    \"\"\"Build the training graph\n",
    "    Args:\n",
    "        logits: Logits tensor, float - [BATCH_SIZE, NUM_CLASSES]\n",
    "        labels: Labels tensor, int32 - [BATCH_SIZE], with values int the range [0, NUM_CLASSES)\n",
    "        learning_rate: The learning rate to use for gradient descent\n",
    "    Returns:\n",
    "        train_op: The Op for training.\n",
    "        loss: The op for calculating loss\n",
    "    \"\"\"\n",
    "    # Create an operation taht calculates loss\n",
    "    labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels, name='xentropy')\n",
    "    loss = tf.reduce_mean(cross_entropy, name='xentropy_mean')\n",
    "    # Craete the fradient descent optimzier with the given learning rate\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    # Create a variable to track the global step\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable = False)\n",
    "    # Use the optimizer to apply yhe gradients that minimize the loss\n",
    "    # (and also increment the global step counter) as a single training step\n",
    "    train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "    \n",
    "    #tf.train.write_graph(tf.get_default_graph().as_graph_def(), '/tmp', \"train.pbtxt\", as_text=True)\n",
    "    \n",
    "    return train_op, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hjkim\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# 2.6 Build the complete graph for feeding inputs, raining, and saving checkpoints\n",
    "mnist_graph = tf.Graph()\n",
    "with mnist_graph.as_default():\n",
    "    # Generate placeholders for the images and labels\n",
    "    images_placeholder = tf.placeholder(tf.float32)\n",
    "    labels_placeholder = tf.placeholder(tf.int32)\n",
    "    tf.add_to_collection(\"images\", images_placeholder)\n",
    "    tf.add_to_collection('labels', labels_placeholder)\n",
    "    \n",
    "    # Build a graph taht compute predictions from teh inference model\n",
    "    logits = mnist_inference(images_placeholder, HIDDEN1_UNITS, HIDDEN2_UNITS)\n",
    "    tf.add_to_collection(\"logits\", logits)\n",
    "    \n",
    "    # Add t o the graph thet ops that calculate and apply gradients\n",
    "    train_op, loss = mnist_training(logits, labels_placeholder, 0.01)\n",
    "    \n",
    "    # Add the variable initializer op\n",
    "    init = tf.initialize_all_variables()\n",
    "    \n",
    "    # Create a saver for writing training checkpoints\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 2.30\n",
      "Step 100: loss = 2.18\n",
      "Step 200: loss = 1.95\n",
      "Step 300: loss = 1.68\n",
      "Step 400: loss = 1.38\n",
      "Step 500: loss = 1.03\n",
      "Step 600: loss = 0.80\n",
      "Step 700: loss = 0.72\n",
      "Step 800: loss = 0.71\n",
      "Step 900: loss = 0.58\n",
      "Step 1000: loss = 0.57\n",
      "Step 1100: loss = 0.67\n",
      "Step 1200: loss = 0.44\n",
      "Step 1300: loss = 0.47\n",
      "Step 1400: loss = 0.62\n",
      "Step 1500: loss = 0.47\n",
      "Step 1600: loss = 0.47\n",
      "Step 1700: loss = 0.47\n",
      "Step 1800: loss = 0.34\n",
      "Step 1900: loss = 0.44\n"
     ]
    }
   ],
   "source": [
    "# 2.7 Run traingin for MAX_STEPS and save checkpoint at the end\n",
    "with tf.Session(graph=mnist_graph) as sess:\n",
    "    # Run the op to initialize the variables\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Start the training loop\n",
    "    for step in xrange(MAX_STEPS):\n",
    "        # Read a batch of images and labels\n",
    "        images_feed, labels_feed = data_sets.train.next_batch(BATCH_SIZE)\n",
    "        \n",
    "        # Run one step of the model. The return values are the activations\n",
    "        # from the `train_op` (which is discarded) and the `loss` op. To\n",
    "        # inspect the values of your ops or variables, you may include them \n",
    "        # in the list passed to sess.run() and the value tensors will be\n",
    "        # returned in the tuple from the call.\n",
    "        _, loss_value = sess.run(\n",
    "            [train_op, loss],\n",
    "            feed_dict = {\n",
    "                images_placeholder: images_feed,\n",
    "                labels_placeholder: labels_feed\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Print out loss value\n",
    "        if step % 100 == 0:\n",
    "            print('Step %d: loss = %.2f' % (step, loss_value))\n",
    "    \n",
    "    # Write a checkpoint\n",
    "    checkpoint_file = os.path.join(TRAIN_DIR, 'checkpoint')\n",
    "    saver.save(sess, checkpoint_file, global_step = step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/mnist\\checkpoint-1999\n",
      "Ground true: 8\n",
      "Prediction: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngiL8QFCEHwiK8ANB/R+I2yPYeyltuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x91e43c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2.8 Run evaluation based on the saved checkpoint.\n",
    "with tf.Session(graph = tf.Graph()) as sess:\n",
    "    saver = tf.train.import_meta_graph(\n",
    "        os.path.join(TRAIN_DIR, \"checkpoint-1999.meta\")\n",
    "    )\n",
    "    saver.restore(\n",
    "        sess, os.path.join(TRAIN_DIR, 'checkpoint-1999')\n",
    "    )\n",
    "    \n",
    "    # Retrieve the ops we remembered\n",
    "    logits = tf.get_collection('logits')[0]\n",
    "    images_placeholder = tf.get_collection('images')[0]\n",
    "    labels_placeholder = tf.get_collection('labels')[0]\n",
    "    \n",
    "    # Add an op taht chooses the top k predictions\n",
    "    eval_op = tf.nn.top_k(logits)\n",
    "    \n",
    "    # Run evaluation\n",
    "    images_feed, labels_feed = data_sets.validation.next_batch(EVAL_BATCH_SIZE)\n",
    "    imgplot = plt.imshow(np.reshape(images_feed, (28, 28)))\n",
    "    prediction = sess.run(eval_op, feed_dict = {\n",
    "        images_placeholder: images_feed,\n",
    "        labels_placeholder: labels_feed\n",
    "    })\n",
    "    print('Ground true: %d\\nPrediction: %d' % (labels_feed, prediction.indices[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
